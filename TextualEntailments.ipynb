{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UmU4RpaGsfVD"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# import modules & set up logging\n",
        "import numpy as np\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Load word2vec pre-train model\n",
        "import gensim.downloader as api\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zWuaFowdeCF",
        "outputId": "9992932e-cf4b-4b81-e201-b1cbd558a8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8aem3hCoZ1Y"
      },
      "source": [
        "## Get all the sentences (text) and the correspondent entailments (hypothesis) from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c3DruEiwXhnY"
      },
      "outputs": [],
      "source": [
        "DS_PATH = \"dataset/rteFormatData\"\n",
        "#DS_PATH = \"/content/drive/MyDrive/Colab Notebooks/ENTAILMENT_GRAPH_ENG_V2.0/data/ENTAILMENT_GRAPH_RTE_FORMAT_ENG_V2.0/rteFormatData\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UJ0iMogK1yBk"
      },
      "outputs": [],
      "source": [
        "files = [f for f in listdir(DS_PATH)]\n",
        "trees = []\n",
        "entailment_pairs = []\n",
        "sentences = []\n",
        "\n",
        "for file in files:\n",
        "    trees.append(ET.parse(DS_PATH+'/'+file))\n",
        "\n",
        "for tree in trees:\n",
        "    root = tree.getroot()\n",
        "    for pair in root.findall('pair'):\n",
        "        if pair.attrib['entailment'] == 'ENTAILMENT':\n",
        "            text = pair.find('t').text.lower()\n",
        "            hypothesis = pair.find('h').text.lower()\n",
        "            sentences.append(text)\n",
        "            sentences.append(hypothesis)\n",
        "            entailment_pairs.append((text, hypothesis))\n",
        "\n",
        "# Remove duplicates\n",
        "entailment_pairs = list(set([i for i in entailment_pairs]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeSDNIhuupuQ"
      },
      "source": [
        "## Get dataset to train the Casual Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENl7Xco2TSdP",
        "outputId": "3c0d870b-eca8-4a35-c96b-6d2353a8fd02"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "050e283cbb794e088b130362d190b356",
            "d42aecf6713040239064e955ce831bde",
            "1a8499e57a394654b819b996006bd97c",
            "13499b22c24b47749433a196e43bbb8c",
            "3b77a8b2c0414e23927fb6cf55d7f470",
            "7fce324835614e79b5722976b566e290",
            "f9d10a3218e74ee7a46ae1645193e2b8",
            "b5005b16fcdf4f16831e34f01b9fdb63",
            "6382b426e1144f5483fb304003d46af4",
            "1273ad13e0f54d70b07bea7550f59cfd",
            "94bd7ce63e5a420381468f61756b925d"
          ]
        },
        "id": "UQnSG7ArZ187",
        "outputId": "86e5ff2d-f2c9-4d87-ccfb-4120c8595542"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset wikitext (C:\\Users\\aless\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-raw-v1\\1.0.0\\a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n",
            "100%|██████████| 3/3 [00:00<00:00, 136.88it/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dSq1CXuUF93J"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def group_texts(examples):\n",
        "    text = ''\n",
        "    for entry in examples:\n",
        "        text += ' ' + entry['text']  \n",
        "    return text\n",
        " \n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mUpS2XSkGgKG"
      },
      "outputs": [],
      "source": [
        "text = group_texts(datasets['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "0SgyLNJ1Glvt",
        "outputId": "95ebcb2d-2908-453f-bc9b-b97e260702ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'   = Valkyria Chronicles III = \\n   Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュ'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6UuiFekhGNc9"
      },
      "outputs": [],
      "source": [
        "c_doc = clean_doc(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRwoCg60HQsD",
        "outputId": "e68b2be0-45d9-4820-aebd-1d8e971b7237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['valkyria', 'chronicles', 'iii', 'senjō', 'no', 'valkyria', 'unrecorded', 'chronicles', 'japanese', 'lit', 'valkyria', 'of', 'the', 'battlefield', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', 'is', 'a', 'tactical', 'role', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'mediavision', 'for', 'the', 'playstation', 'portable', 'released', 'in', 'january', 'in', 'japan', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', 'time', 'gameplay', 'as', 'its', 'predecessors', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', 'nameless', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia', 'during', 'the', 'second', 'europan', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted']\n"
          ]
        }
      ],
      "source": [
        "print(c_doc[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3XO4FX9OeNhW"
      },
      "outputs": [],
      "source": [
        "#datasets['train'][300]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zefEdeVZ3O9I"
      },
      "source": [
        "## Load a pre-trained embedding model for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "exDGC0SNl1o9"
      },
      "outputs": [],
      "source": [
        "#PATH = api.load(\"word2vec-google-news-300\", return_path=True)\n",
        "PATH = \"dataset/word2vec-google-news-300\\word2vec-google-news-300.gz\"\n",
        "#PATH = \"drive/MyDrive/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\"\n",
        "gn_model = word2vec.KeyedVectors.load_word2vec_format(PATH, binary=True)\n",
        "#weights = torch.FloatTensor(gn_model.wv.vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOTBUVVRSzrS"
      },
      "source": [
        "# Training Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLEEjthub92"
      },
      "source": [
        "## Generate vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sWfBumgk5C6O"
      },
      "outputs": [],
      "source": [
        "V = Dictionary([['<PAD>']])\n",
        "V.add_documents([c_doc])\n",
        "\n",
        "for sentence in sentences:\n",
        "    V.add_documents([sentence.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "37MXvljeSzrU"
      },
      "outputs": [],
      "source": [
        "def training_sequence(seq, dictionary):\n",
        "    idxs = dictionary.doc2idx(seq)\n",
        "    # remove unknown tokens\n",
        "    if -1 in idxs: idxs.remove(-1)\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgy3hac0SzrU"
      },
      "source": [
        "## Casual training set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_casual_ds(clean_text, sentence_len=2):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for idx in tqdm(range(len(clean_text) - sentence_len - 1)):\n",
        "        X.append(training_sequence(clean_text[idx:idx+sentence_len], V))\n",
        "        y.append(training_sequence(clean_text[idx+1:idx+1+sentence_len], V))\n",
        "        \n",
        "    X = torch.stack(X_c)\n",
        "    y = torch.stack(y_c)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTgyDWoSzrU",
        "outputId": "aab69ee9-fb39-427f-9b12-364ce0c67e76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 292196/1683470 [00:17<01:21, 17018.49it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/3351673446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_casual_ds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/1998431618.py\u001b[0m in \u001b[0;36mbuild_casual_ds\u001b[1;34m(clean_text, sentence_len)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msentence_len\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msentence_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msentence_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17268/2929712969.py\u001b[0m in \u001b[0;36mtraining_sequence\u001b[1;34m(seq, dictionary)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# remove unknown tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X_c, y_c = build_casual_ds(c_doc, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ8_dCm5Uep5"
      },
      "source": [
        "## Tuning training set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kSPwHH0NSzrW"
      },
      "outputs": [],
      "source": [
        "max_sentence_size = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "    l = len(sentence.lower().split())\n",
        "    if l > max_sentence_size:\n",
        "        max_sentence_size = l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9Btbcv-Tf5H4"
      },
      "outputs": [],
      "source": [
        "def build_tuning_ts(entailment_pairs):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for text, hypothesis in entailment_pairs:\n",
        "        text = text.lower().split()\n",
        "        hypothesis = hypothesis.lower().split()\n",
        "      \n",
        "        if len(text) < max_sentence_size:\n",
        "            text = text + ['<PAD>'] * (max_sentence_size-len(text))\n",
        "        \n",
        "        if len(hypothesis) < max_sentence_size:\n",
        "            hypothesis = hypothesis + ['<PAD>'] * (max_sentence_size-len(hypothesis))\n",
        "        \n",
        "        X.append(training_sequence(text, V))\n",
        "        y.append(training_sequence(hypothesis, V))\n",
        "\n",
        "    X = torch.stack(X)\n",
        "    y = torch.stack(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kGcT0z12gPSK"
      },
      "outputs": [],
      "source": [
        "X_t, y_t = build_tuning_ts(entailment_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpnO5Eab7TJX"
      },
      "source": [
        "## LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jmZQJ4f977TB"
      },
      "outputs": [],
      "source": [
        "class LSTMlm(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMlm, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_size = target_size\n",
        "        self.num_layers = 3\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, \n",
        "                                            embedding_dim, \n",
        "                                            padding_idx=0\n",
        "                                            )\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=self.hidden_dim, \n",
        "                            num_layers=self.num_layers,\n",
        "                            dropout=0.2,\n",
        "                            batch_first=False\n",
        "                            )\n",
        "\n",
        "        # The linear layer that maps from hidden state space to target space\n",
        "        self.hidden2tag = nn.Linear(self.hidden_dim, target_size)\n",
        "\n",
        "    def forward(self, X, X_lengths=[], padding=False):\n",
        "        batch_size, seq_len= X.size()\n",
        "\n",
        "        # ---------------------\n",
        "        # 1. embed the input\n",
        "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len, embedding_dim)\n",
        "        X = self.word_embeddings(X)\n",
        "\n",
        "        # ---------------------\n",
        "        # 2. Run through RNN\n",
        "\n",
        "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
        "        if padding:X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
        "        \n",
        "        # run through LSTM\n",
        "        X, _ = self.lstm(X)\n",
        "        \n",
        "\n",
        "        # undo the packing operation\n",
        "        if padding:X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
        "        \n",
        "        # ---------------------\n",
        "        # 3. Project to tag space\n",
        "\n",
        "        # first we need to reshape the data so it goes into the linear layer\n",
        "        X = X.contiguous()\n",
        "        X = X.view(-1, X.shape[2])\n",
        "\n",
        "        # run through actual linear layer\n",
        "        X = self.hidden2tag(X)\n",
        "\n",
        "        y_hat = F.log_softmax(X, dim=1)\n",
        "        \n",
        "        # reshape back to (batch_size, seq_len, target_size)\n",
        "        y_hat = X.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGDsbjaUGZbL"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YAP59wFRSzrZ"
      },
      "outputs": [],
      "source": [
        "def evaluation_sequence(seq, dictionary):\n",
        "    return [dictionary[token] for token in seq if token in dictionary.key_to_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gtJ5Fj_mtlmS"
      },
      "outputs": [],
      "source": [
        "def compute_cos_sim(sentence1, sentence2):\n",
        "    sentence1 = remove_stopwords(sentence1)\n",
        "    sentence2 = remove_stopwords(sentence2)\n",
        "    sentence1 = torch.Tensor(np.array(evaluation_sequence(sentence1.split(), gn_model))).mean(dim=0)\n",
        "    sentence2 = torch.Tensor(np.array(evaluation_sequence(sentence2.split(), gn_model))).mean(dim=0)\n",
        "    output = F.cosine_similarity(sentence1, sentence2, dim=0)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZVAzS_R_ySIy"
      },
      "outputs": [],
      "source": [
        "def listToString(myList, dictionary=None):\n",
        "    if dictionary != None:\n",
        "        myList = [V[x] for x in myList]\n",
        "    answer = \"\"\n",
        "    for token in myList:\n",
        "        answer += token + \" \"\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GdZJeA_fCtfT"
      },
      "outputs": [],
      "source": [
        "def sentence2sentence(sentence):\n",
        "    model.eval()\n",
        "    sentence = sentence.split()\n",
        "    sequence = training_sequence(sentence, V)\n",
        "\n",
        "    answer_l = []\n",
        "    tensor = model(sequence.view(1, -1))\n",
        "    idxs = torch.argmax(tensor, dim=2).flatten().tolist()\n",
        "    answer_l = [V[v] for v in idxs]\n",
        "\n",
        "    answer = \"\"\n",
        "    for token in answer_l:\n",
        "        #if word != \"<PAD>\":\n",
        "        answer += token + \" \"\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cmnwmQWuzwD2"
      },
      "outputs": [],
      "source": [
        "\"\"\"import math\n",
        "\n",
        "def evaluate_model(entailment_pairs):\n",
        "    cos_sim = []\n",
        "    n_nan = 0\n",
        "    text_target_answer = apply_model(entailment_pairs)\n",
        "    for tri in text_target_answer:\n",
        "        _, target, answer = tri\n",
        "        output = compute_cos_sim(target,answer)\n",
        "        if (math.isnan(output)):\n",
        "            n_nan += 1\n",
        "        else:\n",
        "            cos_sim.append(output)\n",
        "            \n",
        "    mean_cos_sim = sum(cos_sim) / len(cos_sim)\n",
        "    return mean_cos_sim, n_nan\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UYxwLaGVPCny"
      },
      "outputs": [],
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.token2id[w] for w in words[i:]]])\n",
        "        y_pred = model(x)\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.id2token[word_index])\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "BevdiXzoGe7F"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE = 100, 64, len(V), len(V)\n",
        "model = LSTMlm(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE)\n",
        "loss_function = nn.NLLLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaWxrNk4hOdr"
      },
      "source": [
        "## Casual Language Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgNPFOEa18qD",
        "outputId": "52861ef2-0114-45d7-bfb3-2f2b0ef8eae0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n",
            "100%|██████████| 10/10 [01:26<00:00,  8.62s/it]\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "N_SAMPLES = 1000\n",
        "BATCH_SIZE = 100\n",
        "casual_model_loss = []\n",
        "\n",
        "STRIDE = 100000\n",
        "\n",
        "X = X_c[STRIDE:N_SAMPLES+STRIDE]\n",
        "y = y_c[STRIDE:N_SAMPLES+STRIDE]\n",
        "\n",
        "# split dataset into batches\n",
        "X = [X[i:i + BATCH_SIZE] for i in range(0, len(X), BATCH_SIZE)]\n",
        "y = [y[i:i + BATCH_SIZE] for i in range(0, len(y), BATCH_SIZE)]\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "    temp_loss = 0\n",
        "    for idx in tqdm(range(len(X))):\n",
        "        model.zero_grad()\n",
        "        sent = X[idx]\n",
        "        target = y[idx]\n",
        "        scores = model(sent)\n",
        "        loss = loss_function(scores.view(scores.shape[0] * scores.shape[1], -1) , torch.flatten(target))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        temp_loss += loss.item()\n",
        "    casual_model_loss.append(temp_loss/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "aTytZceaYh9y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x2d330401df0>]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, int(N_EPOCHS))\n",
        "plt.plot(epochs, casual_model_loss, 'r', label='Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OcXpxTHQKaW",
        "outputId": "10686c80-6775-4a68-92e0-1ad2fc07218a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['tomorrow', 'morning', 'i', 'will', 'tablebases', 'turing', 'ode', 'slurp', 'liat', 'contrasted', 'ayre', 'wulff', 'website', 'pollock', 'deprecation', 'thurmond', 'flavours', 'disarmament', 'dagestani', 'gurning', 'acrylics', 'singers', 'appendages', 'mesopotamia']\n"
          ]
        }
      ],
      "source": [
        "pred = predict(V, model, \"tomorrow morning i will\", 20)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQor5ieejYV",
        "outputId": "944a61f5-27bd-4b55-883e-dd5bd815520a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  there was no choice between warm and cold dishes on the train \n",
            "target:  diversity of food limited \n",
            "answer:  the the the the the the the the britain the the the  \n",
            "\n",
            "text:  food is execrable \n",
            "target:  food was basically inedible \n",
            "answer:  the the the  \n",
            "\n",
            "text:  the food is disgusting \n",
            "target:  food is awful \n",
            "answer:  the the the the  \n",
            "\n",
            "text:  food was awful \n",
            "target:  food was basically inedible \n",
            "answer:  the the the  \n",
            "\n",
            "text:  food in the undercroft bar was awful \n",
            "target:  the food is awful \n",
            "answer:  the the the the the the the  \n",
            "\n",
            "text:  food is finished too early \n",
            "target:  food portions are small \n",
            "answer:  the the the the the  \n",
            "\n",
            "text:  food could be with more choice \n",
            "target:  the food choices are limted \n",
            "answer:  the the the the the the  \n",
            "\n",
            "text:  food is getting worse \n",
            "target:  food is less impressive than it used to be \n",
            "answer:  the the the the  \n",
            "\n",
            "text:  tickets very expensive \n",
            "target:  selling cheaper tickets \n",
            "answer:  the the the  \n",
            "\n",
            "text:  only comment i can make is the legroom \n",
            "target:  i would like more legroom \n",
            "answer:  the the the the the the the the  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sentence, target in entailment_pairs[:10]:\n",
        "    answer = sentence2sentence(sentence)\n",
        "\n",
        "    print('text: ', sentence, '\\ntarget: ', target, '\\nanswer: ', answer, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi5ZD2wjl4NS"
      },
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/torch_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWwl048xlx9w"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-20LE-FmeF1"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgfU9lMjg-Rr"
      },
      "source": [
        "## Model tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or2eBtXM3Z8L"
      },
      "outputs": [],
      "source": [
        "\"\"\"N_EPOCHS = 10\n",
        "BATCH_SIZE = 100\n",
        "N_SAMPLES = 1000\n",
        "SAMPLE_RATE = 1\n",
        "\n",
        "tuning_model_loss = []\n",
        "cos_sim_mean = []\n",
        "n_nan = []\n",
        "\n",
        "X = X_t[:N_SAMPLES]\n",
        "y = y_t[:N_SAMPLES]\n",
        "\n",
        "# split dataset into batches\n",
        "X = [X[i:i + BATCH_SIZE] for i in range(0, len(X), BATCH_SIZE)]\n",
        "y = [y[i:i + BATCH_SIZE] for i in range(0, len(y), BATCH_SIZE)]\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "    for idx in range(len(X)):\n",
        "        model.zero_grad()\n",
        "        scores = model(X[idx])\n",
        "        target = y[idx]\n",
        "        loss = loss_function(scores.view(scores.shape[0] * scores.shape[1], -1) , torch.flatten(target))\n",
        "        tuning_model_loss.append(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\"\"\"\n",
        "\n",
        "\"\"\"    if idx % SAMPLE_RATE == 0:\n",
        "        mean_, n_nan_ = evaluate_model(entailment_pairs) # <----- sostituire con batched\n",
        "        cos_sim_mean.append(mean_)\n",
        "        n_nan.append(n_nan_)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_MAN5jU5VMT"
      },
      "outputs": [],
      "source": [
        "\"\"\"import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, int(N_EPOCHS/SAMPLE_RATE))\n",
        "plt.plot(epochs, cos_sim_mean, 'g', label='Cosine similarity mean')\"\"\"\n",
        "#plt.plot(epochs, n_nan, 'r', label='Missing answers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9_FvFkt9mFd"
      },
      "outputs": [],
      "source": [
        "\"\"\"plt.plot(epochs, n_nan, 'r', label='Missing answers')\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TextualEntailments.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "430fa73ae8a4b451a46b233c522b61e8748df5b9cb86f0bcabb0032d36e80740"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "050e283cbb794e088b130362d190b356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a8499e57a394654b819b996006bd97c",
              "IPY_MODEL_13499b22c24b47749433a196e43bbb8c",
              "IPY_MODEL_3b77a8b2c0414e23927fb6cf55d7f470"
            ],
            "layout": "IPY_MODEL_d42aecf6713040239064e955ce831bde"
          }
        },
        "1273ad13e0f54d70b07bea7550f59cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13499b22c24b47749433a196e43bbb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6382b426e1144f5483fb304003d46af4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5005b16fcdf4f16831e34f01b9fdb63",
            "value": 3
          }
        },
        "1a8499e57a394654b819b996006bd97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d10a3218e74ee7a46ae1645193e2b8",
            "placeholder": "​",
            "style": "IPY_MODEL_7fce324835614e79b5722976b566e290",
            "value": "100%"
          }
        },
        "3b77a8b2c0414e23927fb6cf55d7f470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94bd7ce63e5a420381468f61756b925d",
            "placeholder": "​",
            "style": "IPY_MODEL_1273ad13e0f54d70b07bea7550f59cfd",
            "value": " 3/3 [00:00&lt;00:00, 27.87it/s]"
          }
        },
        "6382b426e1144f5483fb304003d46af4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fce324835614e79b5722976b566e290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94bd7ce63e5a420381468f61756b925d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5005b16fcdf4f16831e34f01b9fdb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d42aecf6713040239064e955ce831bde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d10a3218e74ee7a46ae1645193e2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
