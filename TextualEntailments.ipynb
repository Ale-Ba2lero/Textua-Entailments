{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextualEntailments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "430fa73ae8a4b451a46b233c522b61e8748df5b9cb86f0bcabb0032d36e80740"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "050e283cbb794e088b130362d190b356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d42aecf6713040239064e955ce831bde",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a8499e57a394654b819b996006bd97c",
              "IPY_MODEL_13499b22c24b47749433a196e43bbb8c",
              "IPY_MODEL_3b77a8b2c0414e23927fb6cf55d7f470"
            ]
          }
        },
        "d42aecf6713040239064e955ce831bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a8499e57a394654b819b996006bd97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7fce324835614e79b5722976b566e290",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9d10a3218e74ee7a46ae1645193e2b8"
          }
        },
        "13499b22c24b47749433a196e43bbb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5005b16fcdf4f16831e34f01b9fdb63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6382b426e1144f5483fb304003d46af4"
          }
        },
        "3b77a8b2c0414e23927fb6cf55d7f470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1273ad13e0f54d70b07bea7550f59cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 27.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94bd7ce63e5a420381468f61756b925d"
          }
        },
        "7fce324835614e79b5722976b566e290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9d10a3218e74ee7a46ae1645193e2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5005b16fcdf4f16831e34f01b9fdb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6382b426e1144f5483fb304003d46af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1273ad13e0f54d70b07bea7550f59cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94bd7ce63e5a420381468f61756b925d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmU4RpaGsfVD"
      },
      "source": [
        "from os import listdir\n",
        "from tqdm import tqdm\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# import modules & set up logging\n",
        "import numpy as np\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "# Load word2vec pre-train model\n",
        "import gensim.downloader as api\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zWuaFowdeCF",
        "outputId": "9992932e-cf4b-4b81-e201-b1cbd558a8ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8aem3hCoZ1Y"
      },
      "source": [
        "## Get all the sentences (text) and the correspondent entailments (hypothesis) from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3DruEiwXhnY"
      },
      "source": [
        "#DS_PATH = \"dataset/rteFormatData\"\n",
        "DS_PATH = \"/content/drive/MyDrive/Colab Notebooks/ENTAILMENT_GRAPH_ENG_V2.0/data/ENTAILMENT_GRAPH_RTE_FORMAT_ENG_V2.0/rteFormatData\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ0iMogK1yBk"
      },
      "source": [
        "files = [f for f in listdir(DS_PATH)]\n",
        "trees = []\n",
        "entailment_pairs = []\n",
        "sentences = []\n",
        "\n",
        "for file in files:\n",
        "    trees.append(ET.parse(DS_PATH+'/'+file))\n",
        "\n",
        "for tree in trees:\n",
        "    root = tree.getroot()\n",
        "    for pair in root.findall('pair'):\n",
        "        if pair.attrib['entailment'] == 'ENTAILMENT':\n",
        "            text = pair.find('t').text.lower()\n",
        "            hypothesis = pair.find('h').text.lower()\n",
        "            sentences.append(text)\n",
        "            sentences.append(hypothesis)\n",
        "            entailment_pairs.append((text, hypothesis))\n",
        "\n",
        "# Remove duplicates\n",
        "entailment_pairs = list(set([i for i in entailment_pairs]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeSDNIhuupuQ"
      },
      "source": [
        "## Get dataset to train the Casual Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENl7Xco2TSdP",
        "outputId": "3c0d870b-eca8-4a35-c96b-6d2353a8fd02"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.16.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.11.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.1.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "050e283cbb794e088b130362d190b356",
            "d42aecf6713040239064e955ce831bde",
            "1a8499e57a394654b819b996006bd97c",
            "13499b22c24b47749433a196e43bbb8c",
            "3b77a8b2c0414e23927fb6cf55d7f470",
            "7fce324835614e79b5722976b566e290",
            "f9d10a3218e74ee7a46ae1645193e2b8",
            "b5005b16fcdf4f16831e34f01b9fdb63",
            "6382b426e1144f5483fb304003d46af4",
            "1273ad13e0f54d70b07bea7550f59cfd",
            "94bd7ce63e5a420381468f61756b925d"
          ]
        },
        "id": "UQnSG7ArZ187",
        "outputId": "86e5ff2d-f2c9-4d87-ccfb-4120c8595542"
      },
      "source": [
        "from datasets import load_dataset\n",
        "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "050e283cbb794e088b130362d190b356",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSq1CXuUF93J"
      },
      "source": [
        "import string\n",
        "\n",
        "def group_texts(examples):\n",
        "    text = ''\n",
        "    for entry in examples:\n",
        "        text += ' ' + entry['text']  \n",
        "    return text\n",
        " \n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUpS2XSkGgKG"
      },
      "source": [
        "text = group_texts(datasets['train'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "0SgyLNJ1Glvt",
        "outputId": "95ebcb2d-2908-453f-bc9b-b97e260702ad"
      },
      "source": [
        "text[:1000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'   = Valkyria Chronicles III = \\n   Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n  The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UuiFekhGNc9"
      },
      "source": [
        "c_doc = clean_doc(text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRwoCg60HQsD",
        "outputId": "e68b2be0-45d9-4820-aebd-1d8e971b7237"
      },
      "source": [
        "print(c_doc[:1000])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['valkyria', 'chronicles', 'iii', 'senjō', 'no', 'valkyria', 'unrecorded', 'chronicles', 'japanese', 'lit', 'valkyria', 'of', 'the', 'battlefield', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', 'is', 'a', 'tactical', 'role', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'mediavision', 'for', 'the', 'playstation', 'portable', 'released', 'in', 'january', 'in', 'japan', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', 'time', 'gameplay', 'as', 'its', 'predecessors', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', 'nameless', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia', 'during', 'the', 'second', 'europan', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'imperial', 'unit', 'calamaty', 'raven', 'the', 'game', 'began', 'development', 'in', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'valkyria', 'chronicles', 'ii', 'while', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', 'it', 'also', 'underwent', 'multiple', 'adjustments', 'such', 'as', 'making', 'the', 'game', 'more', 'forgiving', 'for', 'series', 'newcomers', 'character', 'designer', 'raita', 'honjou', 'and', 'composer', 'hitoshi', 'sakimoto', 'both', 'returned', 'from', 'previous', 'entries', 'along', 'with', 'valkyria', 'chronicles', 'ii', 'director', 'takeshi', 'ozawa', 'a', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', 'the', 'game', 's', 'opening', 'theme', 'was', 'sung', 'by', 'may', 'n', 'it', 'met', 'with', 'positive', 'sales', 'in', 'japan', 'and', 'was', 'praised', 'by', 'both', 'japanese', 'and', 'western', 'critics', 'after', 'release', 'it', 'received', 'downloadable', 'content', 'along', 'with', 'an', 'expanded', 'edition', 'in', 'november', 'of', 'that', 'year', 'it', 'was', 'also', 'adapted', 'into', 'manga', 'and', 'an', 'original', 'video', 'animation', 'series', 'due', 'to', 'low', 'sales', 'of', 'valkyria', 'chronicles', 'ii', 'valkyria', 'chronicles', 'iii', 'was', 'not', 'localized', 'but', 'a', 'fan', 'translation', 'compatible', 'with', 'the', 'game', 's', 'expanded', 'edition', 'was', 'released', 'in', 'mediavision', 'would', 'return', 'to', 'the', 'franchise', 'with', 'the', 'development', 'of', 'valkyria', 'azure', 'revolution', 'for', 'the', 'playstation', 'gameplay', 'as', 'with', 'previous', 'valkyira', 'chronicles', 'games', 'valkyria', 'chronicles', 'iii', 'is', 'a', 'tactical', 'role', 'playing', 'game', 'where', 'players', 'take', 'control', 'of', 'a', 'military', 'unit', 'and', 'take', 'part', 'in', 'missions', 'against', 'enemy', 'forces', 'stories', 'are', 'told', 'through', 'comic', 'book', 'like', 'panels', 'with', 'animated', 'character', 'portraits', 'with', 'characters', 'speaking', 'partially', 'through', 'voiced', 'speech', 'bubbles', 'and', 'partially', 'through', 'unvoiced', 'text', 'the', 'player', 'progresses', 'through', 'a', 'series', 'of', 'linear', 'missions', 'gradually', 'unlocked', 'as', 'maps', 'that', 'can', 'be', 'freely', 'scanned', 'through', 'and', 'replayed', 'as', 'they', 'are', 'unlocked', 'the', 'route', 'to', 'each', 'story', 'location', 'on', 'the', 'map', 'varies', 'depending', 'on', 'an', 'individual', 'player', 's', 'approach', 'when', 'one', 'option', 'is', 'selected', 'the', 'other', 'is', 'sealed', 'off', 'to', 'the', 'player', 'outside', 'missions', 'the', 'player', 'characters', 'rest', 'in', 'a', 'camp', 'where', 'units', 'can', 'be', 'customized', 'and', 'character', 'growth', 'occurs', 'alongside', 'the', 'main', 'story', 'missions', 'are', 'character', 'specific', 'sub', 'missions', 'relating', 'to', 'different', 'squad', 'members', 'after', 'the', 'game', 's', 'completion', 'additional', 'episodes', 'are', 'unlocked', 'some', 'of', 'them', 'having', 'a', 'higher', 'difficulty', 'than', 'those', 'found', 'in', 'the', 'rest', 'of', 'the', 'game', 'there', 'are', 'also', 'love', 'simulation', 'elements', 'related', 'to', 'the', 'game', 's', 'two', 'main', 'heroines', 'although', 'they', 'take', 'a', 'very', 'minor', 'role', 'the', 'game', 's', 'battle', 'system', 'the', 'blitz', 'system', 'is', 'carried', 'over', 'directly', 'from', 'valkyira', 'chronicles', 'during', 'missions', 'players', 'select', 'each', 'unit', 'using', 'a', 'top', 'down', 'perspective', 'of', 'the', 'battlefield', 'map', 'once', 'a', 'character', 'is', 'selected', 'the', 'player', 'moves', 'the', 'character', 'around', 'the', 'battlefield', 'in', 'third', 'person', 'a', 'character', 'can', 'only', 'act', 'once', 'per', 'turn', 'but', 'characters', 'can', 'be', 'granted', 'multiple', 'turns', 'at', 'the', 'expense', 'of', 'other', 'characters', 'turns', 'each', 'character', 'has', 'a', 'field', 'and', 'distance', 'of', 'movement', 'limited', 'by', 'their', 'action', 'gauge', 'up', 'to', 'nine', 'characters', 'can', 'be', 'assigned', 'to', 'a', 'single', 'mission', 'during', 'gameplay', 'characters', 'will', 'call', 'out', 'if', 'something', 'happens', 'to', 'them', 'such', 'as', 'their', 'health', 'points', 'hp', 'getting', 'low', 'or', 'being', 'knocked', 'out', 'by', 'enemy', 'attacks', 'each', 'character', 'has', 'specific', 'potentials', 'skills', 'unique', 'to', 'each', 'character', 'they', 'are', 'divided', 'into', 'personal', 'potential', 'which', 'are', 'innate', 'skills', 'that', 'remain', 'unaltered', 'unless', 'otherwise', 'dictated', 'by', 'the', 'story', 'and', 'can', 'either', 'help', 'or', 'impede', 'a', 'character', 'and', 'battle', 'potentials', 'which', 'are', 'grown', 'throughout', 'the', 'game', 'and', 'always', 'grant', 'boons', 'to', 'a', 'character', 'to', 'learn', 'battle', 'potentials', 'each', 'character', 'has', 'a', 'unique', 'masters', 'table', 'a', 'grid', 'based', 'skill', 'table', 'that', 'can', 'be', 'used', 'to', 'acquire', 'and', 'link', 'different', 'skills', 'characters', 'also', 'have', 'special', 'abilities', 'that', 'grant', 'them', 'temporary', 'boosts', 'on', 'the', 'battlefield', 'kurt', 'can', 'activate', 'direct', 'command', 'and', 'move', 'around', 'the', 'battlefield', 'without', 'depleting', 'his', 'action', 'point', 'gauge', 'the', 'character', 'reila', 'can', 'shift', 'into', 'her', 'valkyria', 'form', 'and', 'become', 'invincible', 'while', 'imca', 'can', 'target', 'multiple', 'enemy', 'units', 'with', 'her', 'heavy', 'weapon', 'troops', 'are', 'divided', 'into', 'five', 'classes', 'scouts', 'shocktroopers', 'engineers', 'lancers', 'and', 'armored', 'soldier', 'troopers', 'can', 'switch', 'classes', 'by', 'changing', 'their', 'assigned', 'weapon', 'changing', 'class', 'does', 'not', 'greatly', 'affect', 'the', 'stats', 'gained', 'while', 'in', 'a', 'previous', 'class', 'with', 'victory', 'in', 'battle', 'experience', 'points', 'are', 'awarded', 'to', 'the', 'squad', 'which', 'are', 'distributed', 'into', 'five', 'different', 'attributes', 'shared', 'by', 'the', 'entire', 'squad', 'a', 'feature', 'differing', 'from', 'early', 'games', 'method', 'of', 'distributing', 'to', 'different', 'unit', 'types', 'plot', 'the', 'game', 'takes', 'place', 'during', 'the', 'second', 'europan', 'war', 'gallian', 'army', 'squad', 'also', 'known', 'as', 'the', 'nameless', 'are', 'a', 'penal', 'military', 'unit', 'composed', 'of', 'criminals', 'foreign', 'deserters', 'and', 'military', 'offenders', 'whose', 'real', 'names', 'are', 'erased', 'from', 'the', 'records', 'and', 'thereon', 'officially', 'referred', 'to', 'by', 'numbers', 'ordered', 'by', 'the', 'gallian', 'military', 'to', 'perform', 'the', 'most', 'dangerous', 'missions', 'that', 'the', 'regular', 'army', 'and', 'militia', 'will', 'not', 'do', 'they', 'are', 'nevertheless', 'up', 'to', 'the', 'task', 'exemplified', 'by', 'their', 'motto', 'altaha', 'abilia', 'meaning', 'always', 'ready', 'the', 'three', 'main', 'characters', 'are', 'kurt', 'irving', 'an', 'army', 'officer', 'falsely', 'accused', 'of', 'treason', 'who', 'wishes', 'to', 'redeem', 'himself', 'ace', 'imca', 'a', 'female', 'darcsen', 'heavy', 'weapons', 'specialist', 'who', 'seeks', 'revenge', 'against', 'the', 'valkyria', 'who', 'destroyed', 'her', 'home', 'and', 'riela', 'marcellis', 'a', 'seemingly', 'jinxed', 'young', 'woman', 'who', 'is', 'unknowingly', 'a', 'descendant', 'of', 'the', 'valkyria', 'together', 'with', 'their', 'fellow', 'squad', 'members', 'these', 'three', 'are', 'tasked', 'to', 'fight', 'against', 'a', 'mysterious', 'imperial', 'unit', 'known', 'as', 'calamity', 'raven', 'consisting', 'of', 'mostly', 'darcsen', 'soldiers', 'as', 'the', 'nameless', 'officially', 'do', 'not', 'exist', 'the', 'upper', 'echelons', 'of', 'the', 'gallian', 'army', 'exploit', 'the', 'concept', 'of', 'plausible', 'deniability', 'in', 'order', 'to', 'send', 'them', 'on', 'missions', 'that', 'would', 'otherwise', 'make', 'gallia', 'lose', 'face', 'in', 'the', 'war', 'while', 'at', 'times', 'this', 'works', 'to', 'their', 'advantage', 'such', 'as', 'a', 'successful', 'incursion', 'into']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XO4FX9OeNhW"
      },
      "source": [
        "#datasets['train'][300]['text']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zefEdeVZ3O9I"
      },
      "source": [
        "## Load a pre-trained embedding model for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exDGC0SNl1o9"
      },
      "source": [
        "#PATH = api.load(\"word2vec-google-news-300\", return_path=True)\n",
        "#PATH = \"dataset/word2vec-google-news-300\\word2vec-google-news-300.gz\"\n",
        "PATH = \"drive/MyDrive/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\"\n",
        "gn_model = word2vec.KeyedVectors.load_word2vec_format(PATH, binary=True)\n",
        "#weights = torch.FloatTensor(gn_model.wv.vectors)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOTBUVVRSzrS"
      },
      "source": [
        "# Training Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FLEEjthub92"
      },
      "source": [
        "## Generate vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWfBumgk5C6O"
      },
      "source": [
        "V = Dictionary([['<PAD>']])\n",
        "V.add_documents([c_doc])\n",
        "\n",
        "for sentence in sentences:\n",
        "    V.add_documents([sentence.split()])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37MXvljeSzrU"
      },
      "source": [
        "def training_sequence(seq, dictionary):\n",
        "    idxs = dictionary.doc2idx(seq)\n",
        "    # remove unknown tokens\n",
        "    if -1 in idxs: idxs.remove(-1)\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgy3hac0SzrU"
      },
      "source": [
        "## Casual training set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCTgyDWoSzrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab69ee9-fb39-427f-9b12-364ce0c67e76"
      },
      "source": [
        "sentence_len = 5\n",
        "n_tokens = len(c_doc)\n",
        "\n",
        "X_c = []\n",
        "y_c = []\n",
        "\n",
        "for idx in tqdm(range(len(c_doc) - sentence_len - 1)):\n",
        "    X_c.append(training_sequence(c_doc[idx:idx+sentence_len], V))\n",
        "    y_c.append(training_sequence(c_doc[idx+1:idx+1+sentence_len], V))\n",
        "    \n",
        "X_c = torch.stack(X_c)\n",
        "y_c = torch.stack(y_c)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1683470/1683470 [00:35<00:00, 47330.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ8_dCm5Uep5"
      },
      "source": [
        "## Tuning training set preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSPwHH0NSzrW"
      },
      "source": [
        "max_sentence_size = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "    l = len(sentence.lower().split())\n",
        "    if l > max_sentence_size:\n",
        "        max_sentence_size = l"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Btbcv-Tf5H4"
      },
      "source": [
        "def build_tuning_ts(entailment_pairs):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for text, hypothesis in entailment_pairs:\n",
        "        text = text.lower().split()\n",
        "        hypothesis = hypothesis.lower().split()\n",
        "      \n",
        "        if len(text) < max_sentence_size:\n",
        "            text = text + ['<PAD>'] * (max_sentence_size-len(text))\n",
        "        \n",
        "        if len(hypothesis) < max_sentence_size:\n",
        "            hypothesis = hypothesis + ['<PAD>'] * (max_sentence_size-len(hypothesis))\n",
        "        \n",
        "        X.append(training_sequence(text, V))\n",
        "        y.append(training_sequence(hypothesis, V))\n",
        "\n",
        "    X = torch.stack(X)\n",
        "    y = torch.stack(y)\n",
        "    return X, y"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGcT0z12gPSK"
      },
      "source": [
        "X_t, y_t = build_tuning_ts(entailment_pairs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpnO5Eab7TJX"
      },
      "source": [
        "## LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmZQJ4f977TB"
      },
      "source": [
        "class LSTMlm(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
        "        super(LSTMlm, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_size = target_size\n",
        "        self.num_layers = 3\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, \n",
        "                                            embedding_dim, \n",
        "                                            padding_idx=0\n",
        "                                            )\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=self.hidden_dim, \n",
        "                            num_layers=self.num_layers,\n",
        "                            dropout=0.2,\n",
        "                            batch_first=False\n",
        "                            )\n",
        "\n",
        "        # The linear layer that maps from hidden state space to target space\n",
        "        self.hidden2tag = nn.Linear(self.hidden_dim, target_size)\n",
        "\n",
        "    def forward(self, X, X_lengths=[], padding=False):\n",
        "        batch_size, seq_len= X.size()\n",
        "\n",
        "        # ---------------------\n",
        "        # 1. embed the input\n",
        "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len, embedding_dim)\n",
        "        X = self.word_embeddings(X)\n",
        "\n",
        "        # ---------------------\n",
        "        # 2. Run through RNN\n",
        "\n",
        "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
        "        if padding:X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
        "        \n",
        "        # run through LSTM\n",
        "        X, _ = self.lstm(X)\n",
        "        \n",
        "\n",
        "        # undo the packing operation\n",
        "        if padding:X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
        "        \n",
        "        # ---------------------\n",
        "        # 3. Project to tag space\n",
        "\n",
        "        # first we need to reshape the data so it goes into the linear layer\n",
        "        X = X.contiguous()\n",
        "        X = X.view(-1, X.shape[2])\n",
        "\n",
        "        # run through actual linear layer\n",
        "        X = self.hidden2tag(X)\n",
        "\n",
        "        y_hat = F.log_softmax(X, dim=1)\n",
        "        \n",
        "        # reshape back to (batch_size, seq_len, target_size)\n",
        "        y_hat = X.view(batch_size, seq_len, -1)\n",
        "\n",
        "        return y_hat"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGDsbjaUGZbL"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAP59wFRSzrZ"
      },
      "source": [
        "def evaluation_sequence(seq, dictionary):\n",
        "    return [dictionary[token] for token in seq if token in dictionary.key_to_index]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtJ5Fj_mtlmS"
      },
      "source": [
        "def compute_cos_sim(sentence1, sentence2):\n",
        "    sentence1 = remove_stopwords(sentence1)\n",
        "    sentence2 = remove_stopwords(sentence2)\n",
        "    sentence1 = torch.Tensor(np.array(evaluation_sequence(sentence1.split(), gn_model))).mean(dim=0)\n",
        "    sentence2 = torch.Tensor(np.array(evaluation_sequence(sentence2.split(), gn_model))).mean(dim=0)\n",
        "    output = F.cosine_similarity(sentence1, sentence2, dim=0)\n",
        "    return output"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVAzS_R_ySIy"
      },
      "source": [
        "def listToString(myList, dictionary=None):\n",
        "    if dictionary != None:\n",
        "        myList = [V[x] for x in myList]\n",
        "    answer = \"\"\n",
        "    for token in myList:\n",
        "        answer += token + \" \"\n",
        "    return answer"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdZJeA_fCtfT"
      },
      "source": [
        "def sentence2sentence(sentence):\n",
        "    model.eval()\n",
        "    sentence = sentence.split()\n",
        "    sequence = training_sequence(sentence, V)\n",
        "\n",
        "    answer_l = []\n",
        "    tensor = model(sequence.view(1, -1))\n",
        "    idxs = torch.argmax(tensor, dim=2).flatten().tolist()\n",
        "    answer_l = [V[v] for v in idxs]\n",
        "\n",
        "    answer = \"\"\n",
        "    for token in answer_l:\n",
        "        #if word != \"<PAD>\":\n",
        "        answer += token + \" \"\n",
        "\n",
        "    return answer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmnwmQWuzwD2"
      },
      "source": [
        "import math\n",
        "\n",
        "def evaluate_model(entailment_pairs):\n",
        "    cos_sim = []\n",
        "    n_nan = 0\n",
        "    text_target_answer = apply_model(entailment_pairs)\n",
        "    for tri in text_target_answer:\n",
        "        _, target, answer = tri\n",
        "        output = compute_cos_sim(target,answer)\n",
        "        if (math.isnan(output)):\n",
        "            n_nan += 1\n",
        "        else:\n",
        "            cos_sim.append(output)\n",
        "            \n",
        "    mean_cos_sim = sum(cos_sim) / len(cos_sim)\n",
        "    return mean_cos_sim, n_nan"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYxwLaGVPCny"
      },
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.token2id[w] for w in words[i:]]])\n",
        "        y_pred = model(x)\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.id2token[word_index])\n",
        "\n",
        "    return words"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BevdiXzoGe7F"
      },
      "source": [
        "EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE = 100, 64, len(V), len(V)\n",
        "model = LSTMlm(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE)\n",
        "loss_function = nn.NLLLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaWxrNk4hOdr"
      },
      "source": [
        "## Casual Language Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgNPFOEa18qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52861ef2-0114-45d7-bfb3-2f2b0ef8eae0"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "N_SAMPLES = 1000000\n",
        "BATCH_SIZE = 100\n",
        "casual_model_loss = []\n",
        "\n",
        "STRIDE = 0\n",
        "\n",
        "X = X_c[STRIDE:N_SAMPLES+STRIDE]\n",
        "y = y_c[STRIDE:N_SAMPLES+STRIDE]\n",
        "\n",
        "# split dataset into batches\n",
        "X = [X[i:i + BATCH_SIZE] for i in range(0, len(X), BATCH_SIZE)]\n",
        "y = [y[i:i + BATCH_SIZE] for i in range(0, len(y), BATCH_SIZE)]\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    temp_loss = 0\n",
        "    for idx in tqdm(range(len(X))):\n",
        "        model.zero_grad()\n",
        "        temp_loss = 0\n",
        "        sent = X[idx]\n",
        "        target = y[idx]\n",
        "        scores = model(sent)\n",
        "        loss = loss_function(scores.view(scores.shape[0] * scores.shape[1], -1) , torch.flatten(target))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        temp_loss += loss\n",
        "    casual_model_loss.append(temp_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2268/10000 [23:36<1:15:29,  1.71it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTytZceaYh9y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, int(N_EPOCHS))\n",
        "plt.plot(epochs, casual_model_loss, 'R', label='Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OcXpxTHQKaW",
        "outputId": "10686c80-6775-4a68-92e0-1ad2fc07218a"
      },
      "source": [
        "predict(V, model, \"i would like to go to\", 20)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'would',\n",
              " 'like',\n",
              " 'to',\n",
              " 'go',\n",
              " 'to',\n",
              " 'alloa',\n",
              " 'beecher',\n",
              " 'kirby',\n",
              " 'admonishes',\n",
              " 'frazee',\n",
              " 'davison',\n",
              " 'threshers',\n",
              " 'vine',\n",
              " 'judiciary',\n",
              " 'mound',\n",
              " 'insurgent',\n",
              " 'occasion',\n",
              " 'shaven',\n",
              " 'bigelow',\n",
              " 'tatty',\n",
              " 'candida',\n",
              " 'equivocal',\n",
              " 'wicketkeeper',\n",
              " 'looks',\n",
              " 'chili']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuyZxwfTfdH6",
        "outputId": "ecb01bbe-8a7b-4a81-9772-c784788912fe"
      },
      "source": [
        "§Q = \"Hello, my name is\"\n",
        "ans = sequence2word(\"Hello, my name is\", 5)\n",
        "print(Q, ans)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is the the the the the \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQor5ieejYV",
        "outputId": "944a61f5-27bd-4b55-883e-dd5bd815520a"
      },
      "source": [
        "for sentence, target in entailment_pairs[:10]:\n",
        "    answer = sentence2sentence(sentence)\n",
        "\n",
        "    print('text: ', sentence, '\\ntarget: ', target, '\\nanswer: ', answer, '\\n')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  cheaper food needed \n",
            "target:  prices are expensive \n",
            "answer:  the the the  \n",
            "\n",
            "text:  leg room is abit uncomfortable \n",
            "target:  disappointed with the amount of legroom \n",
            "answer:  the the the the the  \n",
            "\n",
            "text:  sell better food \n",
            "target:  food is disappointing \n",
            "answer:  the the the  \n",
            "\n",
            "text:  there 's no normal food \n",
            "target:  food is weak \n",
            "answer:  the the the the the  \n",
            "\n",
            "text:  meal is average \n",
            "target:  food mediocre \n",
            "answer:  the the the  \n",
            "\n",
            "text:  have longer opening hours on the phone lines \n",
            "target:  improve customer service experience \n",
            "answer:  the the the the the the the the  \n",
            "\n",
            "text:  little leg room \n",
            "target:  more space seating \n",
            "answer:  the the the  \n",
            "\n",
            "text:  expand the meal options \n",
            "target:  more variety of food would improve service \n",
            "answer:  the the the the  \n",
            "\n",
            "text:  time for the food improved \n",
            "target:  food could be improved \n",
            "answer:  the the the the the  \n",
            "\n",
            "text:  food was bad \n",
            "target:  food could be better \n",
            "answer:  the the the  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi5ZD2wjl4NS"
      },
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Colab Notebooks/torch_model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWwl048xlx9w"
      },
      "source": [
        "torch.save(model.state_dict(), SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-20LE-FmeF1"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgfU9lMjg-Rr"
      },
      "source": [
        "## Model tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or2eBtXM3Z8L"
      },
      "source": [
        "\"\"\"N_EPOCHS = 10\n",
        "BATCH_SIZE = 100\n",
        "N_SAMPLES = 1000\n",
        "SAMPLE_RATE = 1\n",
        "\n",
        "tuning_model_loss = []\n",
        "cos_sim_mean = []\n",
        "n_nan = []\n",
        "\n",
        "X = X_t[:N_SAMPLES]\n",
        "y = y_t[:N_SAMPLES]\n",
        "\n",
        "# split dataset into batches\n",
        "X = [X[i:i + BATCH_SIZE] for i in range(0, len(X), BATCH_SIZE)]\n",
        "y = [y[i:i + BATCH_SIZE] for i in range(0, len(y), BATCH_SIZE)]\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "    for idx in range(len(X)):\n",
        "        model.zero_grad()\n",
        "        scores = model(X[idx])\n",
        "        target = y[idx]\n",
        "        loss = loss_function(scores.view(scores.shape[0] * scores.shape[1], -1) , torch.flatten(target))\n",
        "        tuning_model_loss.append(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\"\"\"\n",
        "\n",
        "\"\"\"    if idx % SAMPLE_RATE == 0:\n",
        "        mean_, n_nan_ = evaluate_model(entailment_pairs) # <----- sostituire con batched\n",
        "        cos_sim_mean.append(mean_)\n",
        "        n_nan.append(n_nan_)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_MAN5jU5VMT"
      },
      "source": [
        "\"\"\"import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(0, int(N_EPOCHS/SAMPLE_RATE))\n",
        "plt.plot(epochs, cos_sim_mean, 'g', label='Cosine similarity mean')\"\"\"\n",
        "#plt.plot(epochs, n_nan, 'r', label='Missing answers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9_FvFkt9mFd"
      },
      "source": [
        "\"\"\"plt.plot(epochs, n_nan, 'r', label='Missing answers')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}